{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Neural networks with Keras I\n",
    "\n",
    "## GRA 4160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. Have a look at the [Keras documentation](https://keras.io/). Install Keras. Try to run the example code in the documentation.\n",
    "2. Go through the code bellow for how to train that train a simple neural network with Keras for classifying the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Neural networks with Keras I\n",
    "\n",
    "# Let's start by importing the necessary libraries and loading the dataset.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# convert target variable to categorical format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Now, we can define the neural network model using Keras.\n",
    "# In this example, we will use a architecture with two hidden layers, each with 16 nodes.\n",
    "\n",
    "# Cefine the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(4,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Adds a layer instance on top of the layer stack.\n",
      "\n",
      "Args:\n",
      "    layer: layer instance.\n",
      "\n",
      "Raises:\n",
      "    TypeError: If `layer` is not a layer instance.\n",
      "    ValueError: In case the `layer` argument does not\n",
      "        know its input shape.\n",
      "    ValueError: In case the `layer` argument has\n",
      "        multiple output tensors, or is already connected\n",
      "        somewhere else (forbidden in `Sequential` models).\n",
      "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/envs/gra4160/lib/python3.10/site-packages/keras/engine/sequential.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "model.add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the softmax activation function for the output layer in this example because it's a multi-class classification problem, where we need to predict one of the three possible classes (setosa, versicolor, or virginica) for each input instance of the iris dataset.\n",
    "\n",
    "The softmax function normalizes the outputs of the last layer of the network into a probability distribution, where the sum of all probabilities is equal to 1. This means that the output of each neuron in the last layer represents the probability of the input belonging to a particular class.\n",
    "\n",
    "Therefore, by using softmax activation function on the output layer, we can obtain the predicted probabilities for each class, and we can select the class with the highest probability as the predicted class for each input instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We need to compile the model by specifying the loss function, optimizer, and evaluation metric.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Crossentropy** is a loss function used for multi-class classification problems where the output variable can take on more than two possible classes.\n",
    "It measures the difference between the true probability distribution and the predicted probability distribution of the output classes.\n",
    "\n",
    "The loss function penalizes the model more if the predicted probability distribution is very different from the true probability distribution.\n",
    "In other words, if the model assigns a low probability to the correct class or a high probability to an incorrect class, the loss function will be high.\n",
    "Conversely, if the model assigns a high probability to the correct class or a low probability to an incorrect class, the loss function will be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 3.1932 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 18:57:59.286221: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5714 - accuracy: 0.3238 - val_loss: 1.4554 - val_accuracy: 0.3556\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3665 - accuracy: 0.3238 - val_loss: 1.0585 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0385 - accuracy: 0.5714 - val_loss: 0.9272 - val_accuracy: 0.6889\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9095 - accuracy: 0.6476 - val_loss: 0.8506 - val_accuracy: 0.7111\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8295 - accuracy: 0.7905 - val_loss: 0.7956 - val_accuracy: 0.6889\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.7143 - val_loss: 0.7675 - val_accuracy: 0.6889\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.6762 - val_loss: 0.7493 - val_accuracy: 0.6444\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.6762 - val_loss: 0.7193 - val_accuracy: 0.6889\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.7810 - val_loss: 0.6928 - val_accuracy: 0.6889\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.7048 - val_loss: 0.6695 - val_accuracy: 0.8889\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.8762 - val_loss: 0.6683 - val_accuracy: 0.6444\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.7048 - val_loss: 0.6308 - val_accuracy: 0.9111\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.8476 - val_loss: 0.6196 - val_accuracy: 0.7111\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.8095 - val_loss: 0.6003 - val_accuracy: 0.7556\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.8286 - val_loss: 0.5871 - val_accuracy: 0.9778\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.9048 - val_loss: 0.5696 - val_accuracy: 0.8222\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.8762 - val_loss: 0.5552 - val_accuracy: 0.8667\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8667 - val_loss: 0.5423 - val_accuracy: 0.9111\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8571 - val_loss: 0.5333 - val_accuracy: 0.9778\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.9429 - val_loss: 0.5416 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7333 - val_loss: 0.5175 - val_accuracy: 0.9333\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.9143 - val_loss: 0.5049 - val_accuracy: 0.9556\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.9429 - val_loss: 0.4941 - val_accuracy: 0.8444\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.8952 - val_loss: 0.4848 - val_accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.8857 - val_loss: 0.4739 - val_accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.8857 - val_loss: 0.4728 - val_accuracy: 0.9556\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.9619 - val_loss: 0.4630 - val_accuracy: 0.9556\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.9333 - val_loss: 0.4589 - val_accuracy: 0.9556\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.9429 - val_loss: 0.4517 - val_accuracy: 0.9556\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.9524 - val_loss: 0.4350 - val_accuracy: 0.9778\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.9524 - val_loss: 0.4420 - val_accuracy: 0.8222\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8952 - val_loss: 0.4245 - val_accuracy: 0.9556\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.9238 - val_loss: 0.4165 - val_accuracy: 0.9778\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.9143 - val_loss: 0.4143 - val_accuracy: 0.9556\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.9524 - val_loss: 0.4041 - val_accuracy: 0.9778\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.9619 - val_loss: 0.3995 - val_accuracy: 0.9778\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.9333 - val_loss: 0.3949 - val_accuracy: 0.9778\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.9333 - val_loss: 0.4061 - val_accuracy: 0.8222\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8857 - val_loss: 0.3850 - val_accuracy: 0.9778\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.9524 - val_loss: 0.3811 - val_accuracy: 0.9778\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.9238 - val_loss: 0.3761 - val_accuracy: 0.9778\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.9429 - val_loss: 0.3723 - val_accuracy: 0.9778\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.9524 - val_loss: 0.3662 - val_accuracy: 0.9778\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.9333 - val_loss: 0.3619 - val_accuracy: 0.9778\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.9619 - val_loss: 0.3638 - val_accuracy: 0.9111\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.9238 - val_loss: 0.3539 - val_accuracy: 0.9778\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.9429 - val_loss: 0.3603 - val_accuracy: 0.8667\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.9238 - val_loss: 0.3463 - val_accuracy: 0.9778\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.9143 - val_loss: 0.3491 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.9143 - val_loss: 0.3403 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x304013310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=50,\n",
    "                            batch_size=32,\n",
    "                            validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.9556\n",
      "Test accuracy: 0.9555555582046509\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
