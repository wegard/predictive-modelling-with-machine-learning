{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Model selection, evaluation, and assessment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Use cross-validation to evaluate the performance of a $k$-nearest neighbors (KNN) model trained on the iris dataset. Vary the number of neighbors and compare the resulting cross-validation scores. Which value of $k$ gives the best performance?\n",
    "2. Train different models, KNN, logistic regression, and decission tree on the iris dataset and compare their performance using accuracy and a confusion matrix. Which model performs best?\n",
    "3. Perform $k$-fold cross-validation on the iris data and compare the performance of several models such as KNN, decision trees, and logistic regression. Which model performs best?\n",
    "4. Train a decision tree on the iris dataset. Use `GridSearchCV` to find the best hyperparameters for `max_depth`, `min_samples_leaf`, and `min_samples_split`. What is the model accuracy with optimized hyperparameters?\n",
    "5. Have a look at: [Scikit-learn: ROC curves](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py) and [Scikit-learn: Precision-Recall](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y,\n",
    "            test_size=0.3, random_state=5)\n",
    "\n",
    "# Define a range of neighbor values\n",
    "k_values = range(1, 21)\n",
    "\n",
    "# Compute the cross-validation scores for each value of k\n",
    "cv_scores = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Plot the cross-validation scores\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(k_values, cv_scores, '-o', lw=2)\n",
    "ax.set_xlabel('Number of neighbors (k)')\n",
    "ax.set_ylabel('Cross-validation score')\n",
    "ax.set_title('KNN performance on the iris dataset')\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal value of k\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "print(f'Optimal number of neighbors: {optimal_k}')\n",
    "\n",
    "# Evaluate the KNN model on the testing set\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn.fit(X_train, y_train)\n",
    "test_score = knn.score(X_test, y_test)\n",
    "print(f'Test set accuracy: {test_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the models to be compared\n",
    "models = [KNeighborsClassifier(), DecisionTreeClassifier(), LogisticRegression(max_iter=1000)]\n",
    "model_names = [\"KNN\", \"Decision Tree\", \"Logistic Regression\"]\n",
    "\n",
    "# Loop over the models\n",
    "for i, model in enumerate(models):\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print the evaluation metrics for this model\n",
    "    print(\"\\nModel: {}\".format(model_names[i]))\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution 3\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Define the models to be compared\n",
    "models = [KNeighborsClassifier(), DecisionTreeClassifier(), LogisticRegression(max_iter=1000)]\n",
    "model_names = [\"KNN\", \"Decision Tree\", \"Logistic Regression\"]\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# Initialize arrays to store the accuracy scores for each model\n",
    "accuracies = np.zeros((len(models), k))\n",
    "\n",
    "# Loop over the models\n",
    "for i, model in enumerate(models):\n",
    "    j = 0\n",
    "    # Loop over the folds\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_kf, X_val_kf = X_train[train_index], X_train[val_index]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Fit the model on the training data for this fold\n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "        # Evaluate the model on the validation data for this fold\n",
    "        y_pred = model.predict(X_val_kf)\n",
    "        accuracy = accuracy_score(y_val_kf, y_pred)\n",
    "        accuracies[i, j] = accuracy\n",
    "        j += 1\n",
    "\n",
    "# Print the average accuracy scores for each model\n",
    "for i, model in enumerate(model_names):\n",
    "    print(\"{}: {:.2f}%\".format(model, np.mean(accuracies[i, :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Solution 4\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid for the decision tree\n",
    "param_grid = {\"max_depth\": [2, 3, 4, 5, 6, None],\n",
    "              \"min_samples_split\": [2, 3, 4, 5, 6],\n",
    "              \"min_samples_leaf\": [1, 2, 3, 4, 5]}\n",
    "\n",
    "# Initialize the decision tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Perform grid search to tune the hyperparameters\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=20, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the performance of the best model on the test data\n",
    "dt_best = grid_search.best_estimator_\n",
    "y_pred = dt_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
