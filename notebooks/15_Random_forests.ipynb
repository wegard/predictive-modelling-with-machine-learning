{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests classifier\n",
    "\n",
    "## Lecture 7\n",
    "\n",
    "### GRA 4160\n",
    "### Predictive modelling with machine learning\n",
    "\n",
    "#### Lecturer: Vegard H. Larsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a random forest from the `DecisionTreeClassifier` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into a pandas dataframe\n",
    "df = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.dropna()\n",
    "df['Sex'] = df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y = df['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to generate a random subset of features\n",
    "def random_subset(n_features):\n",
    "\n",
    "    # Determine the number of features to consider at each split\n",
    "    k = int(np.sqrt(n_features))\n",
    "\n",
    "    # Select a random subset of k features without replacement\n",
    "    features = np.random.choice(n_features, size=k, replace=False)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define a function to train a decision tree on a bootstrapped sample of the data\n",
    "def train_tree(X_train, y_train, n_features):\n",
    "\n",
    "    # Create a bootstrapped sample of the data\n",
    "    n_samples = X_train.shape[0]\n",
    "    sample_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    X_boot = X_train.iloc[sample_indices]\n",
    "    y_boot = y_train.iloc[sample_indices]\n",
    "\n",
    "    # Select a random subset of features\n",
    "    features = random_subset(n_features)\n",
    "    X_boot_subset = X_boot.iloc[:, features]\n",
    "\n",
    "    # Train a decision tree on the bootstrapped sample\n",
    "    dt = DecisionTreeClassifier(max_features=None, random_state=1)\n",
    "    dt.fit(X_boot_subset, y_boot)\n",
    "    return dt, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to predict the class labels for a new data point\n",
    "def predict(X, trees):\n",
    "\n",
    "    # Predict the class label for each tree and aggregate the predictions\n",
    "    y_pred = np.zeros((X.shape[0], len(trees)))\n",
    "    for i, tree in enumerate(trees):\n",
    "        features = tree[1]\n",
    "        X_subset = X.iloc[:, features]\n",
    "        y_pred[:, i] = tree[0].predict(X_subset)\n",
    "\n",
    "    # Convert the predictions to integer type\n",
    "    y_pred = y_pred.astype(int)\n",
    "    y_pred_agg = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=y_pred)\n",
    "    return y_pred_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Train multiple decision trees\n",
    "n_trees = 100\n",
    "max_depth = 3\n",
    "trees = []\n",
    "n_features = X_train.shape[1]\n",
    "for i in range(n_trees):\n",
    "    dt, features = train_tree(X_train, y_train, n_features)\n",
    "    trees.append((dt, features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "\n",
    "y_pred = predict(X_test, trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7391304347826086\n",
      "Precision: 0.7567567567567568\n",
      "Recall: 0.9032258064516129\n",
      "F1: 0.823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate the accuracy of the random forest (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the precision of the random forest (TP /(TP+ FP))\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate the recall of the random forest (TP /(TP+ FN))\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate the F1 score of the random forest (2 * precision * recall / (precision + recall))\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate in test set: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(f'Survival rate in test set: {y_test.sum()/len(y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier object\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=30)\n",
    "\n",
    "# Train the random forest classifier on the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7608695652173914\n",
      "Precision: 0.7631578947368421\n",
      "Recall: 0.9354838709677419\n",
      "F1: 0.8405797101449276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calculate the accuracy of the random forest (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the precision of the random forest (TP /(TP+ FP))\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate the recall of the random forest (TP /(TP+ FN))\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate the F1 score of the random forest (2 * precision * recall / (precision + recall))\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
