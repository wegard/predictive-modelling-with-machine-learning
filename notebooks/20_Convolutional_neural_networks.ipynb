{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Lecture 10\n",
    "\n",
    "### GRA 4160\n",
    "### Predictive modelling with machine learning\n",
    "\n",
    "#### Lecturer: Vegard H. Larsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100 dataset\n",
    "\n",
    "A widely-used benchmark for evaluating machine learning algorithms, particularly in the domain of image classification.\n",
    "It is an extension of the CIFAR-10 dataset, which contains 60,000 32x32-pixel color images, divided into 10 classes with 6,000 images per class.\n",
    "\n",
    "The CIFAR-100 dataset expands upon CIFAR-10 by incorporating 100 fine-grained classes, with each class containing 600 images.\n",
    "These 100 classes are further grouped into 20 coarse-grained classes, each containing 5 fine-grained classes.\n",
    "The dataset is divided into 50,000 training images and 10,000 testing images, with each fine-grained class represented by 500 training images and 100 testing images.\n",
    "\n",
    "The images in the CIFAR-100 dataset are small, low-resolution, and challenging to classify, making it a suitable benchmark for evaluating the performance of various machine learning algorithms and deep learning architectures.\n",
    "Researchers often use this dataset to compare different model architectures, training techniques, and hyperparameter configurations to advance the state of the art in image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Define the fine-grained class names (100 classes)\n",
    "fine_label_list = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck',\n",
    "    'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel',\n",
    "    'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "train_labels = to_categorical(train_labels, num_classes=100)\n",
    "test_labels = to_categorical(test_labels, num_classes=100)\n",
    "\n",
    "# Display a few example images with their labels\n",
    "num_images = 5\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.imshow(train_images[i], interpolation='nearest')\n",
    "    plt.title(fine_label_list[np.argmax(train_labels[i])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d\n",
    "\n",
    "A fundamental building block for many deep learning models, particularly in the domain of image processing and computer vision.\n",
    "The 2D convolutional layer applies a set of learnable filters (also called kernels) to the input, performing a convolution operation to extract local features from the input image or feature map.\n",
    "\n",
    "Each filter in the layer slides over the input, taking a dot product between the filter's weights and the corresponding region of the input.\n",
    "This operation results in a feature map that captures spatial information and local patterns, such as edges, textures, and shapes.\n",
    "As the network becomes deeper, these local patterns can be combined to represent more complex and abstract features.\n",
    "\n",
    "When defining a Conv2D layer in Keras, you need to specify several parameters, such as:\n",
    "\n",
    "1. filters: The number of filters (kernels) in the convolutional layer. This determines the number of feature maps produced by the layer.\n",
    "2. kernel_size: The height and width of the filters. Common choices include (3, 3) and (5, 5).\n",
    "3. strides: The step size used when sliding the filter across the input. A stride of (1, 1) means the filter moves one pixel at a time, while a stride of (2, 2) means it moves two pixels at a time. Larger strides result in smaller feature maps.\n",
    "4. padding: The method used to handle boundaries when applying the filter. Two common options are 'valid' (no padding) and 'same' (padding the input to maintain the same spatial dimensions).\n",
    "5. activation: The activation function applied element-wise to the output feature maps. Common choices include 'relu' (Rectified Linear Unit) and 'tanh' (Hyperbolic Tangent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization\n",
    "\n",
    "Batch normalization is a technique used in deep learning to improve the training process of neural networks.\n",
    "\n",
    "The main idea behind batch normalization is to normalize the activations of each layer in the network so that they have a consistent mean and variance.\n",
    "This is achieved by calculating the mean and variance for each feature across a mini-batch of training examples and then normalizing the activations using these statistics.\n",
    "\n",
    "Batch normalization has several benefits:\n",
    "\n",
    "- **Faster convergence**: By normalizing the inputs to each layer, the gradients become more stable and the optimization process converges more quickly.\n",
    "- **Higher learning rates**: Because the gradients are more stable, higher learning rates can be used without causing the optimization process to diverge or overshoot the optimal solution.\n",
    "- **Regularization effect**: Batch normalization adds a slight noise to the activations, which can have a regularization effect, reducing the risk of overfitting.\n",
    "- **Reduced sensitivity to weight initialization**: With batch normalization, the network becomes less sensitive to the initial values of the weights, allowing for a wider range of weight initialization strategies.\n",
    "\n",
    "In practice, batch normalization is typically applied after the convolutional or fully connected layers in a neural network and before the activation function (e.g., ReLU). However, it's worth noting that there is an ongoing debate about the optimal placement of batch normalization layers in a network architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "Padding refers to the process of adding extra pixels or values around the input image or feature map before applying the convolution operation.\n",
    "Padding is used to control the spatial dimensions of the output feature maps and to preserve the spatial resolution of the input through the network layers.\n",
    "\n",
    "There are two common padding strategies used in CNNs:\n",
    "\n",
    "- \"same\" padding: As mentioned above, this padding strategy ensures that the output feature map has the same spatial dimensions as the input feature map.\n",
    "- \"valid\" padding: This strategy does not add any padding to the input feature map. As a result, the spatial dimensions of the output feature map will be smaller than those of the input feature map, depending on the kernel size and stride used in the convolution operation.\n",
    "\n",
    "The choice of padding strategy depends on the specific requirements of the task and the desired properties of the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "# Import the required libraries\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# Create a Sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# First block: two Conv2D layers with 32 filters, followed by Batch Normalization, MaxPooling2D\n",
    "# The padding=\"same\" parameter in the CNN code means that the padding is applied such that the output feature map has the same spatial dimensions (width and height) as the input feature map.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3))) # 32 filters, (3, 3) kernel size, ReLU activation, and input shape of (32, 32, 3)\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")) # 32 filters, (3, 3) kernel size, ReLU activation\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2))) # Max pooling with pool size (2, 2)\n",
    "model.add(layers.Dropout(0.3)) # Dropout layer with dropout rate of 0.3\n",
    "\n",
    "# Second block: two Conv2D layers with 64 filters, followed by Batch Normalization, MaxPooling2D, and Dropout\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")) # 64 filters, (3, 3) kernel size, ReLU activation\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")) # 64 filters, (3, 3) kernel size, ReLU activation\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2))) # Max pooling with pool size (2, 2)\n",
    "model.add(layers.Dropout(0.5)) # Dropout layer with dropout rate of 0.5\n",
    "\n",
    "# Third block: two Conv2D layers with 128 filters, followed by Batch Normalization, MaxPooling2D, and Dropout\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")) # 128 filters, (3, 3) kernel size, ReLU activation\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")) # 128 filters, (3, 3) kernel size, ReLU activation\n",
    "model.add(layers.BatchNormalization()) # Normalize the activations of the previous layer\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2))) # Max pooling with pool size (2, 2)\n",
    "model.add(layers.Dropout(0.5)) # Dropout layer with dropout rate of 0.5\n",
    "\n",
    "# Flatten the output of the previous block\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layer with 128 nodes and ReLU activation\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Batch Normalization layer\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Dropout layer with dropout rate of 0.5\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer: fully connected layer with 100 nodes and Softmax activation\n",
    "model.add(layers.Dense(100, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
